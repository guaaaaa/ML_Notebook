{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c87f42",
   "metadata": {},
   "source": [
    "# Diffusion model\n",
    "Diffusion model is a type of generative model that uses deep neural networks to take some noisy input and denoise it into something meaningful. The diffusion process has two parts, the forward and the reverse diffusion process. The forward proccess works by first detroying the training data by repeated adding Gassusian noise, then reverse diffusion proccess let the model learns to predict the added noise and remove it to recover the original data. Eventually, after training, we can pass randomly sampled noise to the model and apply the denoising proccess to generate an new data\n",
    "\n",
    "## Forward diffusion process\n",
    "The forward diffusion process, $q$, will iteratively add Gaussian noise to the signal at each time step, $t$, until the last time step, $T$, where the image becomes completely noisy. In essence, this process is a linear combination of the original signal and noise\n",
    "\n",
    "This process is represented by\n",
    "$$x_t = \\alpha_t x_{t-1} + \\sigma_t \\epsilon$$\n",
    "\n",
    "$x_t$: the signal at the current time step, $t$\n",
    "\n",
    "$x_{t-1}$: the signal at previous time step, $t-1$\n",
    "\n",
    "$\\alpha_t$: a coefficient between 0 and 1. It indicates the portion of the signal we want to keep from the previous time step at timestep $t$\n",
    "\n",
    "$\\sigma_t$: a cofficient that indicataes the portion of the noise that we want to add to the signal at timestep $t$. Its value depends on how the noise schedule is defined\n",
    "\n",
    "$\\epsilon$: a noise vector sampled from Gaussian distribution (typically $\\mathcal{N}(0, I)$)\n",
    "\n",
    "Note: $x_0$ represents the original input image and $x_T$ represents the completely noisy signal\n",
    "\n",
    "This represents one step in the forward diffusion process, which combines a portion of the signal from the previous timestep and a portion of newly sampled noise\n",
    "\n",
    "<img src=\"https://www.assemblyai.com/blog/content/images/2022/05/image.png\">\n",
    "\n",
    "In general, we at each timestep, we only want to add a very small portion of noise. This helps preserving the original signal and stablize the training for the reverse diffusion process. If we add all the noise at once, it's impossible for the model to learn predicting what the original image looks like\n",
    "\n",
    "Rewrite of the forward process\n",
    "\n",
    "$$x_t = \\sqrt{\\bar{\\alpha_t}} x_0 + \\sqrt{(1 - \\bar{\\alpha_t})} \\epsilon$$\n",
    "\n",
    "$\\bar{\\alpha_t} = \\Pi_{t=1}^{t} \\alpha_t$: a constant weighting applied to the original image, where $\\alpha_t = 1 - \\beta_t$\n",
    "\n",
    "$\\beta_t$: a linear function that monotonically increases with $t$, meaning $\\bar{\\alpha_t}$ will gradually becomes smaller, and $1 - \\bar{\\alpha_t}$ gradually becomes larger\n",
    "\n",
    "$x_0$: original input image\n",
    "\n",
    "$\\epsilon$: a noise vector sampled from Gaussian distribution (typically $\\mathcal{N}(0, I)$)\n",
    "\n",
    "* At $t=0$, $\\bar{\\alpha_t} = 1$, so $x_t = x_0$ (no noise added)\n",
    "\n",
    "* At $t=T$, $\\bar{\\alpha_t} = 0$, so $x_t = \\epsilon$ (pure noise)\n",
    "\n",
    "This equation represents the cumulative result of gradual noise addition, and we can compute $x_t$ at any time step $t$ directly in one step using the equation for efficiency. However, this is not the same as adding all the noise at once because we can still retrive the signal $x_t$ at any time steps\n",
    "\n",
    "## Reverse diffusion process\n",
    "The reverse diffusion proccess, $p$, will repeatedly remove noise to recover the original image; this is called the sampling or denoising process. \n",
    "\n",
    "<img src=\"https://www.assemblyai.com/blog/content/images/2022/05/image-1.png\">\n",
    "\n",
    "The process starts with $p(x_T) \\sim \\mathcal{N}(x_T,0,I)$ - a completely noisy sample at the final timestep, $T$, and we want to know how the noise was added, $q(x_{t-1}|x_t)$. However, this is not tractable because\n",
    "\n",
    "$$q(x_{t-1} | x_t) = \\frac{q(x_t | x_{t-1}) q(x_{t-1})}{q(x_t)}$$\n",
    "\n",
    "This requires\n",
    "\n",
    "1. $q(x_t | x_{t-1})$: this is known because it’s part of the forward process. It’s a simple Gaussian distribution defined by the noise schedule.\n",
    "\n",
    "2. $q(x_{t-1})$: this is the marginal distribution of $x_{t-1}$, which is intractable to compute directly since it involves integrating over all possible prior states:\n",
    "     $q(x_{t-1}) = \\int q(x_{t-1} | x_0) p(x_0) \\, dx_0$\n",
    "\n",
    "3. $q(x_t)$: Similarly, the marginal $q(x_t)$ requires integrating over $q(x_t | x_0) p(x_0)$, which is computationally infeasible due to the high-dimensional nature of the data.\n",
    "\n",
    "Therefore, we estimate $q(x_{t-1}|x_t)$ with a neural network, $q_{\\theta}(x_{t-1}|x_t)$, parametrized by $\\theta$, the model parameters, which is\n",
    "\n",
    "$$p_{\\theta}(x_0) = p(x_T)\\Pi_{t=1}^{T} p_{\\theta}(x_{t-1}|x_t)$$\n",
    "\n",
    "$p_{\\theta}(x_0)$: the probability of generating $x_0$ using the reverse process\n",
    "\n",
    "$p(x_T)$: the final distribution at $T$ (pure Gaussian noise)\n",
    "\n",
    "$\\Pi_{t=1}^{T} p_{\\theta}(x_{t-1}|x_t)$: the product of all conditional probabilities at each time step, representing the full reverse diffusion process\n",
    "\n",
    "$p_{\\theta}(x_{t-1}|x_t)$: the reverse conditional probability at timestep, $t$ (given $x_t$, predicts $x_{t-1}$). This represents one step of the denoising processs. This can also be written as\n",
    "$$p_{\\theta}(x_{t-1}|x_t) = \\mathcal{N}(x_{t-1},\\mu_\\theta(x_t,t),\\Sigma_\\theta(x_t,t))$$\n",
    "\n",
    "This means at timestep $t$, given $x_t$, the neural network will learns to predict the mean, $\\mu_\\theta(x_t,t)$, and variance, $\\Sigma_\\theta(x_t,t)$, added to the original signal at this timestep\n",
    "\n",
    "This can be reparametrized as\n",
    "$$x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar{\\alpha_t}}} \\epsilon_\\theta(x_t,t)) + \\sigma_t z$$\n",
    "\n",
    "$\\epsilon_\\theta(x_t,t))$: predicted noise at timestep $t$, which is the output of the neural network. It represents the noise added during the forward process that the model learned to estimate\n",
    "\n",
    "$\\frac{\\beta_t}{\\sqrt{1 - \\bar{\\alpha_t}}}$: the portion of the noise component to be subtracted from $x_t$ to denoise it\n",
    "\n",
    "$\\bar{\\alpha_t}$: the cumulative product of noise schedules up to timestep $t$\n",
    "\n",
    "$\\beta_t$: the noise variance for timestep $t$\n",
    "\n",
    "Note: $\\bar{\\alpha_t}$ and $\\beta_t$ represents the same things as the forward process. Essentailly, $x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar{\\alpha_t}}} \\epsilon_\\theta(x_t,t))$ is a rearrangment of the forward equation. It subtracts the predicted noise from $x_t$ to obtain $x_{t-1}$\n",
    "\n",
    "$\\sigma_t$: the standard deviation of the noise to be added during the reverse process at timestep $t$\n",
    "\n",
    "$z$: random Gaussian noise sample\n",
    "\n",
    "The $\\sigma_t z$ term introduce randomness to the reverse process, which prevents it from collapsing to a deterministic process (outputing the average of the dataset). This is very important\n",
    "\n",
    "## Noise scheduler\n",
    "A noise scheduler controlles the noise addition and removal process across multiple time steps to facilitate effective learning and high-quality generation.\n",
    "\n",
    "###  DDPM scheduler\n",
    "DDPM (Denoising Diffusion Probabilistic Models) scheduler is noise scheduler that controls $\\beta_t$, which subsequently influences $\\alpha_t$ ($\\alpha_t = 1 - \\beta_t$), which influences $\\bar {\\alpha_t}$ ($\\bar{\\alpha_t} = \\Pi_{t=1}^{t} \\alpha_t$) to control the addition and removal of noise\n",
    "\n",
    "The noise scheduler controls beta by controlling its\n",
    "1. Intial value: the value of $\\beta_t$ when $t=1$\n",
    "2. Increments: how $\\beta_t$ increases as $t$ increases (linearly, quadratically, or according to a cosine function)\n",
    "3. Final value: the value of $\\beta_t$ when $t=T$\n",
    "\n",
    "### Types of noise schedule\n",
    "* Linear Schedule: increases linearly from a small value to a larger one over (T) steps\n",
    "\n",
    "* Cosine Schedule: Uses a cosine function to vary, providing smoother transitions\n",
    "\n",
    "* Quadratic and Other Non-Linear Schedules: variations that adjust the rate of noise addition in non-linear ways to optimize performance\n",
    "\n",
    "<img src=\"https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10462-023-10504-5/MediaObjects/10462_2023_10504_Fig6_HTML.png\">\n",
    "\n",
    "\n",
    "## Model architecture\n",
    "The model used to predict noise. The neural network takes in the noisy data, $x_t$ and the time step $t$ and output the predicted noise $\\epsilon_\\theta$. The input and output have the exact same size\n",
    "\n",
    "<img src=\"https://www.assemblyai.com/blog/content/images/2022/05/image-19.png\" width=500>\n",
    "\n",
    "* Time embedding: during the sampling process, we need to add the time embedding into the network by encoding the current timestep $t$ into a high-dimensional representation. This tells the model how much noise has been added to the data to help it making appropriate denoising predictions. At a particular timestep, $x_t$ is different from $x_t$ at other timestep due to cumulative noise introduced $1 - \\bar{\\alpha_t}$, so the time embedding is necessary to give the model context on how far along the reverse process it is and how much noise remains to be removed. Without this time context, the model will treats all inputs at different time context the same, which makes it impossible to reconstruct $x_0$. Common time embeddings includes sinusoidal, learned, or hybrid embeddings\n",
    "\n",
    "* Context embedding: related to controlling the generation\n",
    "\n",
    "## Training\n",
    "The training aims to let the model learn to predict how much noise to remove at different timestep\n",
    "\n",
    "Steps:\n",
    "1. Sample clean training images from each batch\n",
    "2. Sample a different timestep for each image in the batch (looking at different timestep stablize the training)\n",
    "3. Sample a random noise for each clean triang image\n",
    "4. Add noise to the clean images based on its corresponding timestep (each image may have a different timestep) to obtain the noisy images (forward diffusion process)\n",
    "5. Input the noisy images and its timestep to the neural network, which outputs the predicted the total amount of noise added to the original data (reverse diffusion process) \n",
    "6. Compute the loss between the predicted noise and the sampled noise using MSE loss function\n",
    "7. Backpropagate using the loss\n",
    "\n",
    "### MSE formula\n",
    "$$L = E_{x_0,\\epsilon}||(\\epsilon_t - \\epsilon_\\theta(x_t,t))||^2$$\n",
    "\n",
    "$\\epsilon_t$: the sampled nosie\n",
    "\n",
    "$\\epsilon_\\theta$: the predicted noise\n",
    "\n",
    "Essentially, we want to minimize the loss function to minimize the distance between the sampled and predicted noise\n",
    "\n",
    "## Controllable generation\n",
    "\n",
    "## DDIM\n",
    "DDPM is slow because its sampling method involves many timesteps and markov chain, so the every next signal $x_{t-1}$ depends on the previous one $x_t$ in the reverse diffusion process. Alternatively, DDIM (Denoising Diffusion Implicit Model) modifies the reverse process to be non-Markovian and deterministic, so it requires less timestep for the reverse process\n",
    "\n",
    "Compared to DDPM, DDIM allows faster training and generation (10-100 times), but the generations will have slightly lower diversity and quality\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/0*gSM9LfAuZA6f914Y.png\">\n",
    "\n",
    "Note: DDPM and DDIM shares the same forware diffusion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462e484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
